{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "#import Path\n",
    "#import torch\n",
    "#import torchvision\n",
    "#import torchvision\n",
    "#from torchvision import models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic', 'im_Parabasal', 'im_Superficial-Intermediate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = models.resnet50\n",
    "#hyperparameters\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "#lr = 0.01 #you can set a specific learning rate or just let it perform cyclic training\n",
    "\n",
    "#Storing path\n",
    "save_loc = 'resnet50model_trainedonSIPAKMEDdataset5000' + str(epochs) + \"batch\" + str(batch_size)\n",
    "\n",
    "## Declaring path of dataset\n",
    "path_img = Path(\"SIPakMed_format\")\n",
    "\n",
    "#Declaring the .pth path for the model weights\n",
    "weights_path = path_img/'models'/\"resnet50modeltrainedon_DA_HERLEV_SIPAKMED95accuracy\"/\"resnet50model_trainedonExtendedDAdataset50batch100.001BEST\"  #this needs to be of .pth extension\n",
    "\n",
    "#Model path (.pkl) to the folder with the \"export.pkl\" seraialization file\n",
    "model_path = path_img/'models'/\"resnet50SimplesipakmedE10B5accuracy87\"   #this needs to be of .pkl extension and it needs to have the name \"export.pkl\"\n",
    "## Loading data \n",
    "data = ImageDataBunch.from_folder(path=path_img, train='train',\n",
    "            valid='val', ds_tfms=get_transforms(), size = 224, bs=batch_size)#, check_ext=False)  #the size of the input pictures is quite important\n",
    "## Normalizing data based on Image net parameters\n",
    "data.normalize(imagenet_stats)\n",
    "#data.show_batch(rows=3, figsize=(10,8))\n",
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 05:12<05:12]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.262541</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='30' class='' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      52.63% [30/57 01:35<01:26 6.9829]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.607312</td>\n",
       "      <td>0.679248</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.772560</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.249996</td>\n",
       "      <td>0.550381</td>\n",
       "      <td>0.840206</td>\n",
       "      <td>0.839481</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.061097</td>\n",
       "      <td>0.548251</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.854509</td>\n",
       "      <td>04:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.846441</td>\n",
       "      <td>0.545085</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.843962</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.813114</td>\n",
       "      <td>0.534080</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.868780</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.785134</td>\n",
       "      <td>0.586233</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.656741</td>\n",
       "      <td>0.528184</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.870992</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.690496</td>\n",
       "      <td>0.557701</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.875570</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.598808</td>\n",
       "      <td>0.431100</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.579593</td>\n",
       "      <td>0.695175</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.812942</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.596356</td>\n",
       "      <td>0.682397</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.860209</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.719765</td>\n",
       "      <td>0.621790</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.734570</td>\n",
       "      <td>0.443431</td>\n",
       "      <td>0.840206</td>\n",
       "      <td>0.840014</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.687034</td>\n",
       "      <td>0.692915</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.787881</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.660407</td>\n",
       "      <td>0.504350</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.645592</td>\n",
       "      <td>0.631698</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.799114</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.658881</td>\n",
       "      <td>1.048674</td>\n",
       "      <td>0.623711</td>\n",
       "      <td>0.596949</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.673199</td>\n",
       "      <td>0.509347</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.834229</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.644489</td>\n",
       "      <td>0.504638</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.844116</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.496060</td>\n",
       "      <td>0.523761</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.489052</td>\n",
       "      <td>0.305791</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.926614</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.423673</td>\n",
       "      <td>0.288199</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.907098</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.439069</td>\n",
       "      <td>0.433186</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.879815</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.387281</td>\n",
       "      <td>0.204681</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932728</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.421670</td>\n",
       "      <td>0.533082</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.832325</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.445213</td>\n",
       "      <td>0.218374</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.922689</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.385988</td>\n",
       "      <td>0.282346</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917451</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.467054</td>\n",
       "      <td>0.312655</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901363</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.409310</td>\n",
       "      <td>0.258374</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.907249</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.304591</td>\n",
       "      <td>0.297042</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.912337</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.357311</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.900427</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.259373</td>\n",
       "      <td>0.367654</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901886</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.282267</td>\n",
       "      <td>0.299432</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.905275</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.208885</td>\n",
       "      <td>0.229672</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927471</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.200848</td>\n",
       "      <td>0.282071</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943220</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.146104</td>\n",
       "      <td>0.214522</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948432</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.174762</td>\n",
       "      <td>0.281414</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948486</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.159545</td>\n",
       "      <td>0.302044</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938133</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.128272</td>\n",
       "      <td>0.261557</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943319</td>\n",
       "      <td>03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.114831</td>\n",
       "      <td>0.333666</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933076</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.134640</td>\n",
       "      <td>0.274588</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938170</td>\n",
       "      <td>03:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>0.255385</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933006</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.089075</td>\n",
       "      <td>0.239986</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932993</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.058526</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933017</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933076</td>\n",
       "      <td>03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.094610</td>\n",
       "      <td>0.237475</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933076</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.084392</td>\n",
       "      <td>0.256709</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>0.233203</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938170</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.042643</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.933076</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.038906</td>\n",
       "      <td>0.262529</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927952</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.7731958627700806.\n",
      "Better model found at epoch 1 with accuracy value: 0.8402062058448792.\n",
      "Better model found at epoch 2 with accuracy value: 0.8556700944900513.\n",
      "Better model found at epoch 4 with accuracy value: 0.8711340427398682.\n",
      "Better model found at epoch 7 with accuracy value: 0.876288652420044.\n",
      "Better model found at epoch 20 with accuracy value: 0.9278350472450256.\n",
      "Better model found at epoch 23 with accuracy value: 0.9329897165298462.\n",
      "Better model found at epoch 34 with accuracy value: 0.9432989954948425.\n",
      "Better model found at epoch 35 with accuracy value: 0.9484536051750183.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "defaults.device = torch.device('cuda')\n",
    "\n",
    "\n",
    "trans_model= cnn_learner(data, models.resnet50, metrics=[accuracy,FBeta(average=\"weighted\")])\n",
    "\n",
    "\n",
    "trans_model.unfreeze()\n",
    "\n",
    "\n",
    "trans_model.lr_find()\n",
    "trans_model.recorder.plot()\n",
    "trans_model.fit_one_cycle(epochs,callbacks=[SaveModelCallback(trans_model, every='improvement', mode = 'max', monitor='accuracy', name=save_loc)])\n",
    "\n",
    "trans_model.save(save_loc)\n",
    "trans_model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
