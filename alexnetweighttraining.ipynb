{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "#import Path\n",
    "#import torch\n",
    "#import torchvision\n",
    "#import torchvision\n",
    "#from torchvision import models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic', 'im_Parabasal', 'im_Superficial-Intermediate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = models.alexnet\n",
    "#hyperparameters\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "#lr = 0.01 #you can set a specific learning rate or just let it perform cyclic training\n",
    "\n",
    "#Storing path\n",
    "save_loc = 'alexnetmodel_trainedonSIPAKMEDdataset5000' + str(epochs) + \"batch\" + str(batch_size)\n",
    "\n",
    "## Declaring path of dataset\n",
    "path_img = Path(\"SIPakMed_format_unaugumented\")\n",
    "\n",
    "#Declaring the .pth path for the model weights\n",
    "weights_path = path_img/'models'/\"alexnetmodeltrainedon_DA_HERLEV_SIPAKMED95accuracy\"/\"alexnetmodel_trainedonExtendedDAdataset50batch100.001BEST\"  #this needs to be of .pth extension\n",
    "\n",
    "#Model path (.pkl) to the folder with the \"export.pkl\" seraialization file\n",
    "model_path = path_img/'models'/\"alexnetSimplesipakmedE10B5accuracy87\"   #this needs to be of .pkl extension and it needs to have the name \"export.pkl\"\n",
    "## Loading data \n",
    "data = ImageDataBunch.from_folder(path=path_img, train='train',\n",
    "            valid='val', ds_tfms=get_transforms(), size = 224, bs=batch_size)#, check_ext=False)  #the size of the input pictures is quite important\n",
    "## Normalizing data based on Image net parameters\n",
    "data.normalize(imagenet_stats)\n",
    "#data.show_batch(rows=3, figsize=(10,8))\n",
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to C:\\Users\\Aditya Arora/.cache\\torch\\hub\\checkpoints\\alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8360620d72d342d7803c1531f00123c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 03:56<03:56]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.283965</td>\n",
       "      <td>#na#</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='29' class='' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.88% [29/57 00:37<00:36 5.5593]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.961414</td>\n",
       "      <td>1.040849</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.581150</td>\n",
       "      <td>02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.541183</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.771870</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.277145</td>\n",
       "      <td>0.608897</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.141808</td>\n",
       "      <td>0.499445</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.824152</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.921952</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.849631</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.836331</td>\n",
       "      <td>0.407057</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.859265</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.737635</td>\n",
       "      <td>0.463409</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.860026</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.846471</td>\n",
       "      <td>0.662749</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.795059</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.895116</td>\n",
       "      <td>0.701642</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.808233</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.831393</td>\n",
       "      <td>0.567906</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.818085</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.429452</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.815604</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.861215</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.825056</td>\n",
       "      <td>1.304046</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.600828</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>1.520083</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.802034</td>\n",
       "      <td>0.644851</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.785309</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.685704</td>\n",
       "      <td>0.958204</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>0.702009</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.676811</td>\n",
       "      <td>1.300303</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.759297</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.644066</td>\n",
       "      <td>1.143157</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.739853</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.646304</td>\n",
       "      <td>2.259000</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.646876</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.693621</td>\n",
       "      <td>0.650001</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.777128</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.614117</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.806609</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.694595</td>\n",
       "      <td>0.850112</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.798896</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.629848</td>\n",
       "      <td>0.550132</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.818492</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.564430</td>\n",
       "      <td>0.555986</td>\n",
       "      <td>0.840206</td>\n",
       "      <td>0.838919</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.511666</td>\n",
       "      <td>0.450573</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.835041</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.492013</td>\n",
       "      <td>0.458624</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.850314</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.529755</td>\n",
       "      <td>0.578817</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.821286</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.410159</td>\n",
       "      <td>0.467424</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.839452</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.356847</td>\n",
       "      <td>0.452512</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.880909</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.381135</td>\n",
       "      <td>0.537029</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.855724</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.331160</td>\n",
       "      <td>0.413787</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.330002</td>\n",
       "      <td>0.405823</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.854635</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.286504</td>\n",
       "      <td>0.431356</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.881218</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.273947</td>\n",
       "      <td>0.665342</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.834590</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.227714</td>\n",
       "      <td>0.323617</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.190007</td>\n",
       "      <td>0.425161</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.907139</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.218962</td>\n",
       "      <td>0.323818</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.881090</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.189651</td>\n",
       "      <td>0.314928</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927780</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.190028</td>\n",
       "      <td>0.361969</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.906792</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.144942</td>\n",
       "      <td>0.367495</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901910</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.124599</td>\n",
       "      <td>0.323441</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.907252</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.123072</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.912542</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.097850</td>\n",
       "      <td>0.280567</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.922796</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.105855</td>\n",
       "      <td>0.317743</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.922774</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.083247</td>\n",
       "      <td>0.329523</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927942</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.087777</td>\n",
       "      <td>0.337927</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917514</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.092454</td>\n",
       "      <td>0.323319</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917564</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.087068</td>\n",
       "      <td>0.338756</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917527</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.342462</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917653</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.080089</td>\n",
       "      <td>0.347611</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.912384</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.5876288414001465.\n",
      "Better model found at epoch 1 with accuracy value: 0.7731958627700806.\n",
      "Better model found at epoch 2 with accuracy value: 0.8195876479148865.\n",
      "Better model found at epoch 3 with accuracy value: 0.8247422575950623.\n",
      "Better model found at epoch 4 with accuracy value: 0.8505154848098755.\n",
      "Better model found at epoch 5 with accuracy value: 0.8608247637748718.\n",
      "Better model found at epoch 28 with accuracy value: 0.8814433217048645.\n",
      "Better model found at epoch 34 with accuracy value: 0.8969072103500366.\n",
      "Better model found at epoch 35 with accuracy value: 0.907216489315033.\n",
      "Better model found at epoch 37 with accuracy value: 0.9278350472450256.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "defaults.device = torch.device('cuda')\n",
    "\n",
    "\n",
    "trans_model= cnn_learner(data, models.alexnet, metrics=[accuracy,FBeta(average=\"weighted\")])\n",
    "\n",
    "trans_model.unfreeze()\n",
    "\n",
    "trans_model.lr_find()\n",
    "trans_model.recorder.plot()\n",
    "trans_model.fit_one_cycle(epochs,callbacks=[SaveModelCallback(trans_model, every='improvement', mode = 'max', monitor='accuracy', name=save_loc)])\n",
    "\n",
    "trans_model.save(save_loc)\n",
    "trans_model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
