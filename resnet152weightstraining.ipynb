{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "#import Path\n",
    "#import torch\n",
    "#import torchvision\n",
    "#import torchvision\n",
    "#from torchvision import models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic', 'im_Parabasal', 'im_Superficial-Intermediate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = models.resnet152\n",
    "#hyperparameters\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "#lr = 0.01 #you can set a specific learning rate or just let it perform cyclic training\n",
    "\n",
    "#Storing path\n",
    "save_loc = 'resnet152model_trainedonSIPAKMEDdataset5000' + str(epochs) + \"batch\" + str(batch_size)\n",
    "\n",
    "## Declaring path of dataset\n",
    "path_img = Path(\"SIPakMed_format_unaugumented\")\n",
    "\n",
    "#Declaring the .pth path for the model weights\n",
    "weights_path = path_img/'models4'/\"resnet152modeltrainedon_DA_HERLEV_SIPAKMED95accuracy\"/\"resnet152model_trainedonExtendedDAdataset50batch100.001BEST\"  #this needs to be of .pth extension\n",
    "\n",
    "#Model path (.pkl) to the folder with the \"export.pkl\" seraialization file\n",
    "model_path = path_img/'models'/\"resnet152SimplesipakmedE10B5accuracy87\"   #this needs to be of .pkl extension and it needs to have the name \"export.pkl\"\n",
    "## Loading data \n",
    "data = ImageDataBunch.from_folder(path=path_img, train='train',\n",
    "            valid='val', ds_tfms=get_transforms(), size = 224, bs=batch_size)#, check_ext=False)  #the size of the input pictures is quite important\n",
    "## Normalizing data based on Image net parameters\n",
    "data.normalize(imagenet_stats)\n",
    "#data.show_batch(rows=3, figsize=(10,8))\n",
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 03:21<03:21]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.320735</td>\n",
       "      <td>#na#</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='31' class='' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      54.39% [31/57 01:51<01:33 8.2175]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.742425</td>\n",
       "      <td>0.776472</td>\n",
       "      <td>0.726804</td>\n",
       "      <td>0.723130</td>\n",
       "      <td>04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.237812</td>\n",
       "      <td>0.656546</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.823194</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.923946</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.705911</td>\n",
       "      <td>0.473963</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.865010</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.703835</td>\n",
       "      <td>0.589913</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.859767</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.600811</td>\n",
       "      <td>0.511575</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.880395</td>\n",
       "      <td>05:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.730793</td>\n",
       "      <td>0.469765</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.860421</td>\n",
       "      <td>04:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.696886</td>\n",
       "      <td>0.659899</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.812770</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.690697</td>\n",
       "      <td>0.539641</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.571714</td>\n",
       "      <td>0.597474</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.830202</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.629258</td>\n",
       "      <td>0.523586</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.847702</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.666144</td>\n",
       "      <td>1.652104</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.640018</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.705084</td>\n",
       "      <td>0.497271</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.807098</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.691646</td>\n",
       "      <td>0.642851</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.732862</td>\n",
       "      <td>0.684277</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.762777</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.604313</td>\n",
       "      <td>0.344771</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.870142</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.675539</td>\n",
       "      <td>0.533288</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.829624</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.662410</td>\n",
       "      <td>0.509314</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.869046</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.734263</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.740877</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.606818</td>\n",
       "      <td>0.386638</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.885090</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.565053</td>\n",
       "      <td>0.452530</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.823515</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>0.529172</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.740751</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.463973</td>\n",
       "      <td>0.505838</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.858602</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.455086</td>\n",
       "      <td>0.485949</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.811096</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.382807</td>\n",
       "      <td>0.409059</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.886523</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.490704</td>\n",
       "      <td>0.450740</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.855081</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.450816</td>\n",
       "      <td>0.278818</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.911423</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.422806</td>\n",
       "      <td>0.240388</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917034</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.383646</td>\n",
       "      <td>0.227162</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.916658</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.300722</td>\n",
       "      <td>0.251214</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.272194</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.906878</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.263588</td>\n",
       "      <td>0.311036</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.212116</td>\n",
       "      <td>0.419264</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.890098</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.248532</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901950</td>\n",
       "      <td>03:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.188532</td>\n",
       "      <td>0.247563</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937618</td>\n",
       "      <td>03:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.191639</td>\n",
       "      <td>0.293931</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932939</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.165480</td>\n",
       "      <td>0.282189</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.922048</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.134214</td>\n",
       "      <td>0.236652</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943268</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.160487</td>\n",
       "      <td>0.239409</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932488</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.118004</td>\n",
       "      <td>0.213615</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938105</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.111690</td>\n",
       "      <td>0.201447</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943303</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.213027</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948339</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.079214</td>\n",
       "      <td>0.288741</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927562</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.079434</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948343</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.080864</td>\n",
       "      <td>0.253450</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.048003</td>\n",
       "      <td>0.247209</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943208</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.054743</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938129</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.066878</td>\n",
       "      <td>0.226794</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943297</td>\n",
       "      <td>03:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.053373</td>\n",
       "      <td>0.210312</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943297</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.045530</td>\n",
       "      <td>0.232537</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943186</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.7268041372299194.\n",
      "Better model found at epoch 1 with accuracy value: 0.8247422575950623.\n",
      "Better model found at epoch 3 with accuracy value: 0.8659793734550476.\n",
      "Better model found at epoch 5 with accuracy value: 0.8814433217048645.\n",
      "Better model found at epoch 19 with accuracy value: 0.8865979313850403.\n",
      "Better model found at epoch 26 with accuracy value: 0.9123711585998535.\n",
      "Better model found at epoch 27 with accuracy value: 0.9175257682800293.\n",
      "Better model found at epoch 29 with accuracy value: 0.938144326210022.\n",
      "Better model found at epoch 37 with accuracy value: 0.9432989954948425.\n",
      "Better model found at epoch 41 with accuracy value: 0.9484536051750183.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "defaults.device = torch.device('cuda')\n",
    "\n",
    "\n",
    "\n",
    "trans_model= cnn_learner(data, models.resnet152, metrics=[accuracy,FBeta(average=\"weighted\")])\n",
    "\n",
    "\n",
    "trans_model.unfreeze()\n",
    "\n",
    "\n",
    "trans_model.lr_find()\n",
    "trans_model.recorder.plot()\n",
    "\n",
    "trans_model.fit_one_cycle(epochs,callbacks=[SaveModelCallback(trans_model, every='improvement', mode = 'max', monitor='accuracy', name=save_loc)])\n",
    "\n",
    "trans_model.save(save_loc)\n",
    "trans_model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
