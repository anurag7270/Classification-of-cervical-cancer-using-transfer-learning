{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic', 'im_Parabasal', 'im_Superficial-Intermediate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\major_project\\env_major_project\\lib\\site-packages\\torch\\nn\\functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = models.densenet169\n",
    "#hyperparameters\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "#lr = 0.01 #you can set a specific learning rate or just let it perform cyclic training\n",
    "\n",
    "#Storing path\n",
    "save_loc = 'densenet169model_trainedonSIPAKMEDdataset5000' + str(epochs) + \"batch\" + str(batch_size)\n",
    "\n",
    "## Declaring path of dataset\n",
    "path_img = Path(\"SIPakMed_format_unaugumented\")\n",
    "\n",
    "#Declaring the .pth path for the model weights\n",
    "weights_path = path_img/'models'/\"densenet16modeltrainedon_DA_HERLEV_SIPAKMED95accuracy\"/\"densenet169model_trainedonExtendedDAdataset50batch100.001BEST\"  #this needs to be of .pth extension\n",
    "\n",
    "#Model path (.pkl) to the folder with the \"export.pkl\" seraialization file\n",
    "model_path = path_img/'models'/\"densenet169SimplesipakmedE10B5accuracy87\"   #this needs to be of .pkl extension and it needs to have the name \"export.pkl\"\n",
    "## Loading data \n",
    "data = ImageDataBunch.from_folder(path=path_img, train='train',\n",
    "            valid='val', ds_tfms=get_transforms(), size = 224, bs=batch_size)#, check_ext=False)  #the size of the input pictures is quite important\n",
    "## Normalizing data based on Image net parameters\n",
    "data.normalize(imagenet_stats)\n",
    "#data.show_batch(rows=3, figsize=(10,8))\n",
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to C:\\Users\\Aditya Arora/.cache\\torch\\hub\\checkpoints\\densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed857878ccb4922ba60c50cc9330205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/54.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 04:18<04:18]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.192945</td>\n",
       "      <td>#na#</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='29' class='' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.88% [29/57 02:20<02:15 6.1068]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.737361</td>\n",
       "      <td>0.762407</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.759325</td>\n",
       "      <td>04:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.186406</td>\n",
       "      <td>0.525893</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.823103</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.487584</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.814874</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.739369</td>\n",
       "      <td>0.453288</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.870440</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.653572</td>\n",
       "      <td>0.441688</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.885843</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.643252</td>\n",
       "      <td>0.664235</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.826614</td>\n",
       "      <td>04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.634120</td>\n",
       "      <td>0.422820</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901610</td>\n",
       "      <td>04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563504</td>\n",
       "      <td>0.512342</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.869940</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.632971</td>\n",
       "      <td>0.404854</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.865035</td>\n",
       "      <td>04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.603115</td>\n",
       "      <td>0.391642</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.900916</td>\n",
       "      <td>04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.594674</td>\n",
       "      <td>0.379135</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.880983</td>\n",
       "      <td>04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.739972</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.813513</td>\n",
       "      <td>04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.459518</td>\n",
       "      <td>0.323413</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.907033</td>\n",
       "      <td>04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.549008</td>\n",
       "      <td>0.273927</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.906797</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.486223</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.895733</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.519055</td>\n",
       "      <td>0.725782</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.803196</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.536794</td>\n",
       "      <td>0.749516</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.807322</td>\n",
       "      <td>04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.436928</td>\n",
       "      <td>0.405412</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.885163</td>\n",
       "      <td>04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.486580</td>\n",
       "      <td>0.393777</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.875947</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.471572</td>\n",
       "      <td>0.546273</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.394054</td>\n",
       "      <td>0.320354</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937882</td>\n",
       "      <td>05:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.371878</td>\n",
       "      <td>0.520375</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.872559</td>\n",
       "      <td>06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.466617</td>\n",
       "      <td>0.322604</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.880451</td>\n",
       "      <td>05:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>0.191253</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937755</td>\n",
       "      <td>05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.286973</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937674</td>\n",
       "      <td>05:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.252646</td>\n",
       "      <td>0.230495</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932280</td>\n",
       "      <td>05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.288885</td>\n",
       "      <td>0.375559</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>05:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.288578</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.902062</td>\n",
       "      <td>0.901343</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.253121</td>\n",
       "      <td>0.224377</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927324</td>\n",
       "      <td>05:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>0.169716</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937970</td>\n",
       "      <td>05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.145619</td>\n",
       "      <td>0.326509</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.912145</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.156697</td>\n",
       "      <td>0.267536</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.917254</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.133026</td>\n",
       "      <td>0.399858</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.891057</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.164936</td>\n",
       "      <td>0.275360</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932465</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.147037</td>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948484</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.273315</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.922464</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.106030</td>\n",
       "      <td>0.162538</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948374</td>\n",
       "      <td>04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.080836</td>\n",
       "      <td>0.193191</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943145</td>\n",
       "      <td>04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.081404</td>\n",
       "      <td>0.216206</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938151</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>0.229728</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948491</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.072777</td>\n",
       "      <td>0.222052</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948374</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.061603</td>\n",
       "      <td>0.218064</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927592</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.222824</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.932652</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.033038</td>\n",
       "      <td>0.242787</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943224</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.247184</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943222</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.242622</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937665</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.233902</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948261</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.943172</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.044837</td>\n",
       "      <td>0.241123</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.937952</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.040733</td>\n",
       "      <td>0.236391</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.948310</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.7628865838050842.\n",
      "Better model found at epoch 1 with accuracy value: 0.8247422575950623.\n",
      "Better model found at epoch 3 with accuracy value: 0.8711340427398682.\n",
      "Better model found at epoch 4 with accuracy value: 0.8865979313850403.\n",
      "Better model found at epoch 6 with accuracy value: 0.9020618796348572.\n",
      "Better model found at epoch 12 with accuracy value: 0.907216489315033.\n",
      "Better model found at epoch 20 with accuracy value: 0.938144326210022.\n",
      "Better model found at epoch 34 with accuracy value: 0.9484536051750183.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "defaults.device = torch.device('cuda')\n",
    "trans_model= cnn_learner(data, models.densenet169, metrics=[accuracy,FBeta(average=\"weighted\")])\n",
    "\n",
    "trans_model.unfreeze()\n",
    "trans_model.lr_find()\n",
    "trans_model.recorder.plot()\n",
    "trans_model.fit_one_cycle(epochs,callbacks=[SaveModelCallback(trans_model, every='improvement', mode = 'max', monitor='accuracy', name=save_loc)])\n",
    "\n",
    "trans_model.save(save_loc)\n",
    "trans_model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
